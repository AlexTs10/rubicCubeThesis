{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Algorithm Comparison: Thistlethwaite vs Kociemba vs Korf\n",
    "\n",
    "**Author:** Alex Toska  \n",
    "**Affiliation:** University of Patras  \n",
    "**Phase:** 9 (Demos & UI Visualization)  \n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides a comprehensive comparison of the three implemented solving algorithms using the Phase 8 evaluation framework.\n",
    "\n",
    "We'll compare:\n",
    "- **Solution quality** (number of moves)\n",
    "- **Speed** (computation time)\n",
    "- **Memory usage**\n",
    "- **Success rates**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from src.cube.rubik_cube import RubikCube\n",
    "from src.evaluation.algorithm_comparison import AlgorithmComparison\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úì Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-comparison",
   "metadata": {},
   "source": [
    "## Part 1: Single Scramble Comparison\n",
    "\n",
    "Let's compare all three algorithms on a single scramble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-test",
   "metadata": {},
   "outputs": [],
   "source": "# Create scramble\ncube = RubikCube()\ncube.scramble(moves=10, seed=42)\nscramble = getattr(cube, '_scramble_moves', [])\n\nprint(f\"Scramble: {' '.join(scramble)}\")\nprint(f\"Depth: {len(scramble)} moves\\n\")\n\n# Initialize comparison framework\ncomparison = AlgorithmComparison(\n    thistlethwaite_timeout=30.0,\n    kociemba_timeout=60.0,\n    korf_timeout=120.0,\n    korf_max_depth=20\n)\n\n# Run comparison\nresult = comparison.compare_on_scramble(cube, scramble_id=0)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results in a table\n",
    "data = []\n",
    "for name, algo_result in [\n",
    "    (\"Thistlethwaite\", result.thistlethwaite),\n",
    "    (\"Kociemba\", result.kociemba),\n",
    "    (\"Korf IDA*\", result.korf)\n",
    "]:\n",
    "    if algo_result.solved:\n",
    "        data.append({\n",
    "            \"Algorithm\": name,\n",
    "            \"Solved\": \"‚úì\",\n",
    "            \"Moves\": algo_result.solution_length,\n",
    "            \"Time (s)\": f\"{algo_result.time_seconds:.3f}\",\n",
    "            \"Memory (MB)\": f\"{algo_result.memory_mb:.2f}\"\n",
    "        })\n",
    "    else:\n",
    "        data.append({\n",
    "            \"Algorithm\": name,\n",
    "            \"Solved\": \"‚úó\",\n",
    "            \"Moves\": \"-\",\n",
    "            \"Time (s)\": f\"{algo_result.time_seconds:.3f}\",\n",
    "            \"Memory (MB)\": f\"{algo_result.memory_mb:.2f}\"\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"\\n=== Comparison Results ===\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch-comparison",
   "metadata": {},
   "source": [
    "## Part 2: Batch Comparison\n",
    "\n",
    "Test all algorithms on multiple scrambles for statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run batch test\n",
    "print(\"Running batch test on 10 scrambles...\\n\")\n",
    "\n",
    "results = comparison.run_batch_test(\n",
    "    n_scrambles=10,\n",
    "    scramble_depth=10,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Batch test complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics\n",
    "summaries = comparison.generate_summary()\n",
    "\n",
    "# Display summary\n",
    "summary_data = []\n",
    "for name in ['Thistlethwaite', 'Kociemba', 'Korf_IDA*']:\n",
    "    s = summaries[name]\n",
    "    summary_data.append({\n",
    "        \"Algorithm\": name.replace('_', ' '),\n",
    "        \"Success Rate\": f\"{s.success_rate * 100:.1f}%\",\n",
    "        \"Avg Moves\": f\"{s.avg_solution_length:.1f}\",\n",
    "        \"Avg Time (s)\": f\"{s.avg_time_seconds:.3f}\",\n",
    "        \"Avg Memory (MB)\": f\"{s.avg_memory_mb:.2f}\"\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n=== Summary Statistics ===\")\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualizations",
   "metadata": {},
   "source": [
    "## Part 3: Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-moves",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot solution length comparison\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "algorithms = ['Thistlethwaite', 'Kociemba', 'Korf_IDA*']\n",
    "labels = ['Thistlethwaite', 'Kociemba', 'Korf IDA*']\n",
    "colors = ['#3498db', '#2ecc71', '#9b59b6']\n",
    "\n",
    "# Solution length\n",
    "moves = [summaries[alg].avg_solution_length for alg in algorithms]\n",
    "ax1.bar(labels, moves, color=colors, alpha=0.7)\n",
    "ax1.set_ylabel('Moves')\n",
    "ax1.set_title('Average Solution Length')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Time\n",
    "times = [summaries[alg].avg_time_seconds for alg in algorithms]\n",
    "ax2.bar(labels, times, color=colors, alpha=0.7)\n",
    "ax2.set_ylabel('Seconds')\n",
    "ax2.set_title('Average Solving Time')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Memory\n",
    "memory = [summaries[alg].avg_memory_mb for alg in algorithms]\n",
    "ax3.bar(labels, memory, color=colors, alpha=0.7)\n",
    "ax3.set_ylabel('MB')\n",
    "ax3.set_title('Average Memory Usage')\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "winner-analysis",
   "metadata": {},
   "source": [
    "## Part 4: Winner Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "winners",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üèÜ Winner Analysis\\n\")\n",
    "\n",
    "# Fewest moves\n",
    "moves_data = [(name.replace('_', ' '), summaries[name].avg_solution_length) \n",
    "              for name in algorithms]\n",
    "winner = min(moves_data, key=lambda x: x[1])\n",
    "print(f\"Fewest Moves: {winner[0]} ({winner[1]:.1f} avg)\")\n",
    "\n",
    "# Fastest\n",
    "time_data = [(name.replace('_', ' '), summaries[name].avg_time_seconds) \n",
    "             for name in algorithms]\n",
    "winner = min(time_data, key=lambda x: x[1])\n",
    "print(f\"Fastest: {winner[0]} ({winner[1]:.3f}s avg)\")\n",
    "\n",
    "# Least memory\n",
    "mem_data = [(name.replace('_', ' '), summaries[name].avg_memory_mb) \n",
    "            for name in algorithms]\n",
    "winner = min(mem_data, key=lambda x: x[1])\n",
    "print(f\"Least Memory: {winner[0]} ({winner[1]:.2f} MB avg)\")\n",
    "\n",
    "# Best success rate\n",
    "success_data = [(name.replace('_', ' '), summaries[name].success_rate) \n",
    "                for name in algorithms]\n",
    "winner = max(success_data, key=lambda x: x[1])\n",
    "print(f\"Best Success Rate: {winner[0]} ({winner[1] * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Thistlethwaite** is the fastest but produces sub-optimal solutions\n",
    "2. **Kociemba** offers the best balance of speed and solution quality\n",
    "3. **Korf IDA*** finds optimal solutions but can be slower\n",
    "\n",
    "### Trade-offs\n",
    "\n",
    "| Algorithm | Best For |\n",
    "|-----------|----------|\n",
    "| Thistlethwaite | Quick demos, educational purposes |\n",
    "| Kociemba | Practical solving, competitions |\n",
    "| Korf IDA* | Research, optimal solutions |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try different scramble depths (5, 10, 15, 20)\n",
    "- Increase sample size for better statistics\n",
    "- Compare with Phase 8 comprehensive results\n",
    "- Experiment with different timeout settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export",
   "metadata": {},
   "source": [
    "## Export Results\n",
    "\n",
    "Uncomment and run to export results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to JSON\n",
    "# comparison.export_results('../results/notebook_comparison.json')\n",
    "\n",
    "# Export summary to Markdown\n",
    "# comparison.export_summary_table('../results/notebook_summary.md', format='markdown')\n",
    "\n",
    "print(\"Export complete (if uncommented)!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}